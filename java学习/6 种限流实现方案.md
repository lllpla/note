# 6 种限流实现方案
## 限流分类
限流的实现方案有很多种，磊哥这里稍微理了一下，限流的分类如下所示：

1. 合法性验证限流：比如验证码、IP 黑名单等，这些手段可以有效的防止恶意攻击和爬虫采集；
2. 容器限流：比如 Tomcat、Nginx 等限流手段，其中 Tomcat 可以设置最大线程数（maxThreads），当并发超过最大线程数会排队等待执行；而 Nginx 提供了两种限流手段：一是控制速率，二是控制并发连接数；
3. 服务端限流：比如我们在服务器端通过限流算法实现限流，此项也是我们本文介绍的重点。

合法性验证限流为最常规的业务代码，就是普通的验证码和 IP 黑名单系统，本文就不做过多的叙述了，我们重点来看下后两种限流的实现方案：容器限流和服务端限流。

## 容器限流

### Tomcat限流

以tomcat8.5版本为例，最大线程数再conf/server.xml配置中，如下所示：

```xml
<Connector port="8080" protocol="HTTP/1.1"
          connectionTimeout="20000"
          maxThreads="150"
          redirectPort="8443" />
```

其中`maxThreads`就是tomcat的最大线程数，当请求的并发大于此值时，请求就会排队执行，以达到限流的目的

>maxThreads 的值可以适当的调大一些，此值默认为 150（Tomcat 版本 8.5.42），但这个值也不是越大越好，要看具体的硬件配置，需要注意的是每开启一个线程需要耗用 1MB 的 JVM 内存空间用于作为线程栈之用，并且线程越多 GC 的负担也越重。最后需要注意一下，操作系统对于进程中的线程数有一定的限制，Windows 每个进程中的线程数不允许超过 2000，Linux 每个进程中的线程数不允许超过 1000。

### Nginx限流

Nginx提供了两种限流手段：一是控制速率，二是控制并发连接数。

#### 控制速率

我们需要使用`limit_req_zone`来限制单位时间内的请求数，即速率限制，配置示例如下：

```json
limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s;
server { 
    location / { 
        limit_req zone=mylimit;
    }
}
```

以上配置表示，限制每个 IP 访问的速度为 2r/s，因为 Nginx 的限流统计是基于毫秒的，我们设置的速度是 2r/s，转换一下就是 500ms 内单个 IP 只允许通过 1 个请求，从 501ms 开始才允许通过第 2 个请求。

我们使用单 IP 在 10ms 内发并发送了 6 个请求的执行结果如下：
![title](https://raw.githubusercontent.com/lllpla/img/master/gitnote/2020/05/18/1589765420579-1589765420639.png)
从以上结果可以看出他的执行符合我们的预期，只有 1 个执行成功了，其他的 5 个被拒绝了（第 2 个在 501ms 才会被正常执行）。

#### 速率限制升级版

上面的速录控制虽然很精准，但是用于真实环境未免太苛刻了，真实情况下我们应该控制一个ip单位总时间内的总访问次数，而不是像上面那么精确到毫秒。因此我们可以使用`burst`关键字开启此设置，示例配置如下：

```json
limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s;
server { 
    location / { 
        limit_req zone=mylimit burst=4;
    }
}
```

burst=4 表示每个 IP 最多允许4个突发请求，如果单个 IP 在 10ms 内发送 6 次请求的结果如下：
![title](https://raw.githubusercontent.com/lllpla/img/master/gitnote/2020/05/18/1589765583581-1589765583583.png)
从以上结果可以看出，有 1 个请求被立即处理了，4 个请求被放到 burst 队列里排队执行了，另外 1 个请求被拒绝了。

#### 控制并发数

利用`limit_conn_zone`和`limit_conn`两个指令即可控制并发数，示例配置如下：

```json
limit_conn_zone $binary_remote_addr zone=perip:10m;
limit_conn_zone $server_name zone=perserver:10m;
server {
    ...
    limit_conn perip 10;
    limit_conn perserver 100;
}
```

其中 limit_conn perip 10 表示限制单个 IP 同时最多能持有 10 个连接；limit_conn perserver 100 表示 server 同时能处理并发连接的总数为 100 个。

> 只有当 request header 被后端处理后，这个连接才进行计数。

### 服务端限流

服务端限流要配合限流算法来执行，常见的限流算法有以下三种：

1. 时间窗口算法
2. 漏桶算法
3. 令牌算法

#### 1. 时间窗口算法

所谓的滑动时间算法指的是以当前时间为截止时间，往前取一定的时间，比如往前取 60s 的时间，在这 60s 之内运行最大的访问数为 100，此时算法的执行逻辑为，先清除 60s 之前的所有请求记录，再计算当前集合内请求数量是否大于设定的最大请求数 100，如果大于则执行限流拒绝策略，否则插入本次请求记录并返回可以正常执行的标识给客户端。

滑动窗口如下图所示：

![title](https://raw.githubusercontent.com/lllpla/img/master/gitnote/2020/05/18/1589766983170-1589766983172.png)

其中每一小个表示 10s，被红色虚线包围的时间段则为需要判断的时间间隔，比如 60s 秒允许 100 次请求，那么红色虚线部分则为 60s。

我们可以借助 Redis 的有序集合 ZSet 来实现时间窗口算法限流，实现的过程是先使用 ZSet 的 key 存储限流的 ID，score 用来存储请求的时间，每次有请求访问来了之后，先清空之前时间窗口的访问量，统计现在时间窗口的个数和最大允许访问量对比，如果大于等于最大访问量则返回 false 执行限流操作，负责允许执行业务逻辑，并且在 ZSet 中添加一条有效的访问记录，具体实现代码如下。

我们借助 Jedis 包来操作 Redis，实现在 pom.xml 添加 Jedis 框架的引用，配置如下：

```xml

```